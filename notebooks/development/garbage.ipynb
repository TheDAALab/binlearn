{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace705b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class MeanImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_means=None):\n",
    "        self.feature_means = feature_means\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_means = np.nanmean(X, axis=0).tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return np.where(np.isnan(X), self.feature_means, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c62a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = MeanImputer()\n",
    "imputer.fit([[1, np.nan], [3, 4]])\n",
    "params = imputer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d53084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_means': [2.0, 4.0]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  'feature_means': [2.0, 4.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929fff6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_means': [2.0, 4.0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f11a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_string = json.dumps(imputer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bb77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.loads(json_string)\n",
    "restored = MeanImputer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf98e6d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type MeanImputer is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: simplify(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params.items()}\n\u001b[32m     33\u001b[39m safe_params = to_json_safe_params(best.get_params(deep=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m params_json = json.dumps(safe_params, indent=\u001b[32m2\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(params_json)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Deserialize manually (for demonstration)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/binning/lib/python3.13/json/__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    235\u001b[39m     skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    236\u001b[39m     check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    237\u001b[39m     separators=separators, default=default, sort_keys=sort_keys,\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     **kw).encode(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/binning/lib/python3.13/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28mself\u001b[39m.iterencode(o, _one_shot=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/binning/lib/python3.13/json/encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _iterencode(o, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/binning/lib/python3.13/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type MeanImputer is not JSON serializable"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Dataset and simulated missing values\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X[::10] = np.nan  # simulate missing data\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', MeanImputer()),\n",
    "    ('clf', LogisticRegression(max_iter=500))\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid={\n",
    "    'clf__C': [0.1, 1.0, 10.0]\n",
    "})\n",
    "\n",
    "grid.fit(X, y)\n",
    "best = grid.best_estimator_\n",
    "\n",
    "# Serialize best estimator's parameters\n",
    "# Extract only the JSON-safe parts of the params\n",
    "def to_json_safe_params(params):\n",
    "    def simplify(v):\n",
    "        if isinstance(v, BaseEstimator):\n",
    "            return v.get_params()\n",
    "        return v\n",
    "    return {k: simplify(v) for k, v in params.items()}\n",
    "\n",
    "safe_params = to_json_safe_params(best.get_params(deep=True))\n",
    "params_json = json.dumps(safe_params, indent=2)\n",
    "print(params_json)\n",
    "\n",
    "# Deserialize manually (for demonstration)\n",
    "params_dict = json.loads(params_json)\n",
    "reconstructed = Pipeline([\n",
    "    ('imputer', MeanImputer(**params_dict['imputer'])),\n",
    "    ('clf', LogisticRegression(max_iter=500, C=params_dict['clf__C']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0503ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('imputer',\n",
       "   MeanImputer(feature_means=[5.83777777777778, 3.0548148148148155,\n",
       "                              3.751851851851853, 1.1940740740740745])),\n",
       "  ('clf', LogisticRegression(C=10.0, max_iter=500))],\n",
       " 'transform_input': None,\n",
       " 'verbose': False,\n",
       " 'imputer': MeanImputer(feature_means=[5.83777777777778, 3.0548148148148155,\n",
       "                            3.751851851851853, 1.1940740740740745]),\n",
       " 'clf': LogisticRegression(C=10.0, max_iter=500),\n",
       " 'imputer__feature_means': [5.83777777777778,\n",
       "  3.0548148148148155,\n",
       "  3.751851851851853,\n",
       "  1.1940740740740745],\n",
       " 'clf__C': 10.0,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__dual': False,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__l1_ratio': None,\n",
       " 'clf__max_iter': 500,\n",
       " 'clf__multi_class': 'deprecated',\n",
       " 'clf__n_jobs': None,\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': None,\n",
       " 'clf__solver': 'lbfgs',\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56f672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
