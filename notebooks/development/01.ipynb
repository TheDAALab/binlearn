{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72e9641",
   "metadata": {},
   "source": [
    "# EqualWidthBinning Comprehensive Demo\n",
    "\n",
    "This notebook demonstrates the main functionalities of EqualWidthBinning:\n",
    "1. **Array binning** - Working with NumPy arrays\n",
    "2. **Pandas integration** - DataFrame support\n",
    "3. **Polars integration** - Modern DataFrame library support  \n",
    "4. **Sklearn integration** - Pipeline compatibility\n",
    "5. **Serialization/Deserialization** - Parameter persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "118ed5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "Polars available: True\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    import polars as pl\n",
    "    POLARS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    POLARS_AVAILABLE = False\n",
    "    print(\"Polars not available - skipping polars examples\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Import our binning classes\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "from binning.methods import EqualWidthBinning\n",
    "from binning import get_config, set_config\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"Polars available: {POLARS_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de76f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array shape: (1000, 3)\n",
      "Data ranges: uniform [0.5, 100.0], normal [6.2, 97.9], exponential [0.0, 122.6]\n",
      "\n",
      "Pandas DataFrame shape: (1000, 4)\n",
      "Columns: ['uniform', 'normal', 'exponential', 'bimodal']\n",
      "\n",
      "Polars DataFrame shape: (1000, 4)\n",
      "Columns: ['uniform', 'normal', 'exponential', 'bimodal']\n"
     ]
    }
   ],
   "source": [
    "# Create sample data for demonstrations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data with different distributions\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'uniform': np.random.uniform(0, 100, n_samples),\n",
    "    'normal': np.random.normal(50, 15, n_samples),\n",
    "    'exponential': np.random.exponential(2, n_samples) * 10,\n",
    "    'bimodal': np.concatenate([\n",
    "        np.random.normal(30, 5, n_samples//2),\n",
    "        np.random.normal(70, 5, n_samples//2)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create NumPy array (2D)\n",
    "X_array = np.column_stack([data['uniform'], data['normal'], data['exponential']])\n",
    "print(f\"NumPy array shape: {X_array.shape}\")\n",
    "print(f\"Data ranges: uniform [{X_array[:, 0].min():.1f}, {X_array[:, 0].max():.1f}], \"\n",
    "      f\"normal [{X_array[:, 1].min():.1f}, {X_array[:, 1].max():.1f}], \"\n",
    "      f\"exponential [{X_array[:, 2].min():.1f}, {X_array[:, 2].max():.1f}]\")\n",
    "\n",
    "# Create pandas DataFrame\n",
    "df_pandas = pd.DataFrame(data)\n",
    "print(f\"\\nPandas DataFrame shape: {df_pandas.shape}\")\n",
    "print(f\"Columns: {list(df_pandas.columns)}\")\n",
    "\n",
    "# Create polars DataFrame (if available)\n",
    "if POLARS_AVAILABLE:\n",
    "    df_polars = pl.DataFrame(data)\n",
    "    print(f\"\\nPolars DataFrame shape: {df_polars.shape}\")\n",
    "    print(f\"Columns: {df_polars.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7cd91e",
   "metadata": {},
   "source": [
    "## 1. Array Binning - NumPy Integration\n",
    "\n",
    "EqualWidthBinning works seamlessly with NumPy arrays, providing flexible binning options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce3d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Array Binning ===\n",
      "Basic binner: EqualWidthBinning(n_bins=5, clip=True, preserve_dataframe=False, fit_jointly=False)\n",
      "Original data shape: (1000, 3)\n",
      "Binned data shape: (1000, 3)\n",
      "Bin indices range: [0, 4]\n",
      "First 5 rows original:\n",
      "[[37.45401188 52.66551501 71.17997798]\n",
      " [95.07143064 29.96983462  8.04980097]\n",
      " [73.19939418 55.70296777 13.15718605]\n",
      " [59.86584842 59.15878618  4.36555101]\n",
      " [15.60186404 58.39685672 18.8722145 ]]\n",
      "First 5 rows binned:\n",
      "[[1 2 2]\n",
      " [4 1 0]\n",
      " [3 2 0]\n",
      " [2 2 0]\n",
      " [0 2 0]]\n",
      "\n",
      "Bin edges per column:\n",
      "  Column 0: ['0.46', '20.36', '40.27', '60.17', '80.07', '99.97']\n",
      "  Column 1: ['6.18', '24.52', '42.87', '61.21', '79.55', '97.90']\n",
      "  Column 2: ['0.00', '24.52', '49.03', '73.55', '98.06', '122.58']\n",
      "\n",
      "=== Per-column bin configuration ===\n",
      "Custom binner: EqualWidthBinning(n_bins={0: 3, 1: 7, 2: 4}, clip=True, preserve_dataframe=False, fit_jointly=False)\n",
      "Custom binned shape: (1000, 3)\n",
      "Unique bins per column:\n",
      "  Column 0: 3 unique bins -> [0 1 2]\n",
      "  Column 1: 7 unique bins -> [0 1 2 3 4 5 6]\n",
      "  Column 2: 4 unique bins -> [0 1 2 3]\n",
      "\n",
      "Inverse transform shape: (1000, 3)\n",
      "First 5 rows reconstructed:\n",
      "[[50.21748481 52.03817813 76.61037468]\n",
      " [83.38700649 25.83335791 15.32226109]\n",
      " [83.38700649 52.03817813 15.32226109]\n",
      " [50.21748481 65.14058824 15.32226109]\n",
      " [17.04796314 52.03817813 15.32226109]]\n"
     ]
    }
   ],
   "source": [
    "# Basic array binning\n",
    "print(\"=== Basic Array Binning ===\")\n",
    "\n",
    "# Simple binning with default parameters\n",
    "binner_basic = EqualWidthBinning(n_bins=5)\n",
    "print(f\"Basic binner: {repr(binner_basic)}\")\n",
    "\n",
    "# Fit and transform\n",
    "binner_basic.fit(X_array)\n",
    "X_binned = binner_basic.transform(X_array)\n",
    "\n",
    "print(f\"Original data shape: {X_array.shape}\")\n",
    "print(f\"Binned data shape: {X_binned.shape}\")\n",
    "print(f\"Bin indices range: [{X_binned.min()}, {X_binned.max()}]\")\n",
    "print(f\"First 5 rows original:\\n{X_array[:5]}\")\n",
    "print(f\"First 5 rows binned:\\n{X_binned[:5]}\")\n",
    "\n",
    "# Show bin edges for each column\n",
    "print(f\"\\nBin edges per column:\")\n",
    "for col, edges in binner_basic._bin_edges.items():\n",
    "    print(f\"  Column {col}: {[f'{e:.2f}' for e in edges]}\")\n",
    "\n",
    "# Different number of bins per column\n",
    "print(\"\\n=== Per-column bin configuration ===\")\n",
    "binner_custom = EqualWidthBinning(n_bins={0: 3, 1: 7, 2: 4})\n",
    "print(f\"Custom binner: {repr(binner_custom)}\")\n",
    "\n",
    "binner_custom.fit(X_array)\n",
    "X_binned_custom = binner_custom.transform(X_array)\n",
    "\n",
    "print(f\"Custom binned shape: {X_binned_custom.shape}\")\n",
    "print(f\"Unique bins per column:\")\n",
    "for i in range(X_binned_custom.shape[1]):\n",
    "    unique_bins = np.unique(X_binned_custom[:, i])\n",
    "    print(f\"  Column {i}: {len(unique_bins)} unique bins -> {unique_bins}\")\n",
    "\n",
    "# Inverse transform\n",
    "X_reconstructed = binner_custom.inverse_transform(X_binned_custom)\n",
    "print(f\"\\nInverse transform shape: {X_reconstructed.shape}\")\n",
    "print(f\"First 5 rows reconstructed:\\n{X_reconstructed[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c37e0e",
   "metadata": {},
   "source": [
    "## 2. Pandas Integration\n",
    "\n",
    "EqualWidthBinning preserves DataFrame structure and column names when `preserve_dataframe=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5286a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pandas DataFrame Integration ===\n",
      "Pandas binner: EqualWidthBinning(n_bins=4, clip=True, preserve_dataframe=True, fit_jointly=False)\n",
      "Original DataFrame type: <class 'pandas.core.frame.DataFrame'>\n",
      "Binned DataFrame type: <class 'pandas.core.frame.DataFrame'>\n",
      "Preserved columns: ['uniform', 'normal', 'exponential', 'bimodal']\n",
      "Binned DataFrame shape: (1000, 4)\n",
      "\n",
      "Original data (first 5 rows):\n",
      "     uniform     normal  exponential    bimodal\n",
      "0  37.454012  52.665515    71.179978  36.187191\n",
      "1  95.071431  29.969835     8.049801  27.713492\n",
      "2  73.199394  55.702968    13.157186  29.785883\n",
      "3  59.865848  59.158786     4.365551  30.290114\n",
      "4  15.601864  58.396857    18.872215  34.242154\n",
      "\n",
      "Binned data (first 5 rows):\n",
      "   uniform  normal  exponential  bimodal\n",
      "0        1       2            2        1\n",
      "1        3       1            0        0\n",
      "2        2       2            0        0\n",
      "3        2       2            0        0\n",
      "4        0       2            0        1\n",
      "\n",
      "Bin statistics per column:\n",
      "  uniform: bins 0-3, unique bins: 4\n",
      "  normal: bins 0-3, unique bins: 4\n",
      "  exponential: bins 0-3, unique bins: 4\n",
      "  bimodal: bins 0-3, unique bins: 4\n",
      "\n",
      "Subset binning:\n",
      "  Input columns: ['uniform', 'normal']\n",
      "  Output columns: ['uniform', 'normal']\n",
      "  Output shape: (1000, 2)\n",
      "\n",
      "Inverse transform (first 5 rows):\n",
      "     uniform     normal  exponential    bimodal\n",
      "0  37.778914  63.502787    76.610375  41.030956\n",
      "1  87.533197  40.573569    15.322261  23.706532\n",
      "2  62.656055  63.502787    15.322261  23.706532\n",
      "3  62.656055  63.502787    15.322261  23.706532\n",
      "4  12.901773  63.502787    15.322261  41.030956\n"
     ]
    }
   ],
   "source": [
    "# Pandas DataFrame binning\n",
    "print(\"=== Pandas DataFrame Integration ===\")\n",
    "\n",
    "# Bin with DataFrame preservation\n",
    "binner_pandas = EqualWidthBinning(n_bins=4, preserve_dataframe=True, clip=True)\n",
    "print(f\"Pandas binner: {repr(binner_pandas)}\")\n",
    "\n",
    "# Fit and transform DataFrame\n",
    "binner_pandas.fit(df_pandas)\n",
    "df_binned = binner_pandas.transform(df_pandas)\n",
    "\n",
    "print(f\"Original DataFrame type: {type(df_pandas)}\")\n",
    "print(f\"Binned DataFrame type: {type(df_binned)}\")\n",
    "print(f\"Preserved columns: {list(df_binned.columns)}\")\n",
    "print(f\"Binned DataFrame shape: {df_binned.shape}\")\n",
    "\n",
    "print(f\"\\nOriginal data (first 5 rows):\")\n",
    "print(df_pandas.head())\n",
    "\n",
    "print(f\"\\nBinned data (first 5 rows):\")\n",
    "print(df_binned.head())\n",
    "\n",
    "# Show statistics per column\n",
    "print(f\"\\nBin statistics per column:\")\n",
    "for col in df_binned.columns:\n",
    "    print(f\"  {col}: bins {df_binned[col].min()}-{df_binned[col].max()}, \"\n",
    "          f\"unique bins: {df_binned[col].nunique()}\")\n",
    "\n",
    "# Working with specific columns only\n",
    "subset_columns = ['uniform', 'normal']\n",
    "df_subset = df_pandas[subset_columns]\n",
    "\n",
    "binner_subset = EqualWidthBinning(n_bins=6, preserve_dataframe=True)\n",
    "binner_subset.fit(df_subset)\n",
    "df_subset_binned = binner_subset.transform(df_subset)\n",
    "\n",
    "print(f\"\\nSubset binning:\")\n",
    "print(f\"  Input columns: {list(df_subset.columns)}\")\n",
    "print(f\"  Output columns: {list(df_subset_binned.columns)}\")\n",
    "print(f\"  Output shape: {df_subset_binned.shape}\")\n",
    "\n",
    "# Inverse transform back to original values (representatives)\n",
    "df_reconstructed = binner_pandas.inverse_transform(df_binned)\n",
    "print(f\"\\nInverse transform (first 5 rows):\")\n",
    "print(df_reconstructed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3d353",
   "metadata": {},
   "source": [
    "## 3. Polars Integration\n",
    "\n",
    "EqualWidthBinning also supports Polars DataFrames with automatic format detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5bd370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Polars DataFrame Integration ===\n",
      "Polars binner: EqualWidthBinning(n_bins=5, clip=True, preserve_dataframe=True, fit_jointly=False)\n",
      "Original Polars DataFrame type: <class 'polars.dataframe.frame.DataFrame'>\n",
      "Binned Polars DataFrame type: <class 'polars.dataframe.frame.DataFrame'>\n",
      "Preserved columns: ['uniform', 'normal', 'exponential', 'bimodal']\n",
      "Binned DataFrame shape: (1000, 4)\n",
      "\n",
      "Original data (first 5 rows):\n",
      "shape: (5, 4)\n",
      "┌───────────┬───────────┬─────────────┬───────────┐\n",
      "│ uniform   ┆ normal    ┆ exponential ┆ bimodal   │\n",
      "│ ---       ┆ ---       ┆ ---         ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ f64         ┆ f64       │\n",
      "╞═══════════╪═══════════╪═════════════╪═══════════╡\n",
      "│ 37.454012 ┆ 52.665515 ┆ 71.179978   ┆ 36.187191 │\n",
      "│ 95.071431 ┆ 29.969835 ┆ 8.049801    ┆ 27.713492 │\n",
      "│ 73.199394 ┆ 55.702968 ┆ 13.157186   ┆ 29.785883 │\n",
      "│ 59.865848 ┆ 59.158786 ┆ 4.365551    ┆ 30.290114 │\n",
      "│ 15.601864 ┆ 58.396857 ┆ 18.872215   ┆ 34.242154 │\n",
      "└───────────┴───────────┴─────────────┴───────────┘\n",
      "\n",
      "Binned data (first 5 rows):\n",
      "shape: (5, 4)\n",
      "┌─────────┬────────┬─────────────┬─────────┐\n",
      "│ uniform ┆ normal ┆ exponential ┆ bimodal │\n",
      "│ ---     ┆ ---    ┆ ---         ┆ ---     │\n",
      "│ i64     ┆ i64    ┆ i64         ┆ i64     │\n",
      "╞═════════╪════════╪═════════════╪═════════╡\n",
      "│ 1       ┆ 2      ┆ 2           ┆ 1       │\n",
      "│ 4       ┆ 1      ┆ 0           ┆ 0       │\n",
      "│ 3       ┆ 2      ┆ 0           ┆ 1       │\n",
      "│ 2       ┆ 2      ┆ 0           ┆ 1       │\n",
      "│ 0       ┆ 2      ┆ 0           ┆ 1       │\n",
      "└─────────┴────────┴─────────────┴─────────┘\n",
      "\n",
      "Unique bins per column:\n",
      "  uniform: 5 unique bins, range [0, 4]\n",
      "  normal: 5 unique bins, range [0, 4]\n",
      "  exponential: 5 unique bins, range [0, 4]\n",
      "  bimodal: 5 unique bins, range [0, 4]\n",
      "\n",
      "Inverse transform (first 5 rows):\n",
      "shape: (5, 4)\n",
      "┌───────────┬───────────┬─────────────┬───────────┐\n",
      "│ uniform   ┆ normal    ┆ exponential ┆ bimodal   │\n",
      "│ ---       ┆ ---       ┆ ---         ┆ ---       │\n",
      "│ f64       ┆ f64       ┆ f64         ┆ f64       │\n",
      "╞═══════════╪═══════════╪═════════════╪═══════════╡\n",
      "│ 30.315772 ┆ 52.038178 ┆ 61.288346   ┆ 35.833629 │\n",
      "│ 90.020911 ┆ 33.694804 ┆ 12.257855   ┆ 21.97409  │\n",
      "│ 70.119198 ┆ 52.038178 ┆ 12.257855   ┆ 35.833629 │\n",
      "│ 50.217485 ┆ 52.038178 ┆ 12.257855   ┆ 35.833629 │\n",
      "│ 10.414059 ┆ 52.038178 ┆ 12.257855   ┆ 35.833629 │\n",
      "└───────────┴───────────┴─────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Polars DataFrame binning (if available)\n",
    "if POLARS_AVAILABLE:\n",
    "    print(\"=== Polars DataFrame Integration ===\")\n",
    "    \n",
    "    # Bin with Polars DataFrame preservation\n",
    "    binner_polars = EqualWidthBinning(n_bins=5, preserve_dataframe=True)\n",
    "    print(f\"Polars binner: {repr(binner_polars)}\")\n",
    "    \n",
    "    # Fit and transform Polars DataFrame\n",
    "    binner_polars.fit(df_polars)\n",
    "    df_polars_binned = binner_polars.transform(df_polars)\n",
    "    \n",
    "    print(f\"Original Polars DataFrame type: {type(df_polars)}\")\n",
    "    print(f\"Binned Polars DataFrame type: {type(df_polars_binned)}\")\n",
    "    print(f\"Preserved columns: {df_polars_binned.columns}\")\n",
    "    print(f\"Binned DataFrame shape: {df_polars_binned.shape}\")\n",
    "    \n",
    "    print(f\"\\nOriginal data (first 5 rows):\")\n",
    "    print(df_polars.head())\n",
    "    \n",
    "    print(f\"\\nBinned data (first 5 rows):\")\n",
    "    print(df_polars_binned.head())\n",
    "    \n",
    "    # Show unique bins per column\n",
    "    print(f\"\\nUnique bins per column:\")\n",
    "    for col in df_polars_binned.columns:\n",
    "        unique_count = df_polars_binned[col].n_unique()\n",
    "        min_val = df_polars_binned[col].min()\n",
    "        max_val = df_polars_binned[col].max()\n",
    "        print(f\"  {col}: {unique_count} unique bins, range [{min_val}, {max_val}]\")\n",
    "        \n",
    "    # Inverse transform\n",
    "    df_polars_reconstructed = binner_polars.inverse_transform(df_polars_binned)\n",
    "    print(f\"\\nInverse transform (first 5 rows):\")\n",
    "    print(df_polars_reconstructed.head())\n",
    "    \n",
    "else:\n",
    "    print(\"Polars not available - skipping polars demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8d0c4",
   "metadata": {},
   "source": [
    "## 4. Sklearn Integration\n",
    "\n",
    "EqualWidthBinning is fully compatible with sklearn pipelines and follows sklearn conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4e0bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sklearn Pipeline Integration ===\n",
      "Pipeline steps: ['binner', 'scaler']\n",
      "Training set shape: (700, 3)\n",
      "Test set shape: (300, 3)\n",
      "Pipeline fitted successfully\n",
      "Transformed training shape: (700, 3)\n",
      "Transformed test shape: (300, 3)\n",
      "Binner is fitted: True\n",
      "Number of features in: 3\n",
      "\n",
      "Bin edges from pipeline:\n",
      "  Column 0: 8 bins, range [0.46, 99.97]\n",
      "  Column 1: 8 bins, range [6.92, 97.90]\n",
      "  Column 2: 8 bins, range [0.00, 122.58]\n",
      "\n",
      "Scaler statistics (mean, std):\n",
      "  Column 0: mean=3.451, std=2.351\n",
      "  Column 1: mean=3.447, std=1.366\n",
      "  Column 2: mean=0.839, std=1.226\n",
      "\n",
      "=== Pipeline Parameters ===\n",
      "Binner parameters in pipeline:\n",
      "  binner__bin_edges: {0: [np.float64(0.4632023004602859), np.float64(12.901772928979383), np.float64(25.34034355749848), np.float64(37.77891418601758), np.float64(50.217484814536675), np.float64(62.65605544305577), np.float64(75.09462607157487), np.float64(87.53319670009395), np.float64(99.97176732861305)], 1: [np.float64(6.916066800775262), np.float64(18.288635140387466), np.float64(29.66120347999967), np.float64(41.03377181961188), np.float64(52.40634015922408), np.float64(63.77890849883628), np.float64(75.1514768384485), np.float64(86.5240451780607), np.float64(97.8966135176729)], 2: [np.float64(0.00023269646100864647), np.float64(15.322261094163599), np.float64(30.64428949186619), np.float64(45.966317889568785), np.float64(61.288346287271374), np.float64(76.61037468497396), np.float64(91.93240308267656), np.float64(107.25443148037914), np.float64(122.57645987808174)]}\n",
      "  binner__bin_range: None\n",
      "  binner__bin_representatives: {0: [np.float64(6.682487614719834), np.float64(19.12105824323893), np.float64(31.55962887175803), np.float64(43.998199500277124), np.float64(56.436770128796226), np.float64(68.87534075731531), np.float64(81.31391138583442), np.float64(93.7524820143535)], 1: [np.float64(12.602350970581364), np.float64(23.97491931019357), np.float64(35.34748764980577), np.float64(46.72005598941798), np.float64(58.09262432903018), np.float64(69.46519266864239), np.float64(80.8377610082546), np.float64(92.2103293478668)], 2: [np.float64(7.661246895312304), np.float64(22.983275293014895), np.float64(38.30530369071749), np.float64(53.627332088420076), np.float64(68.94936048612267), np.float64(84.27138888382527), np.float64(99.59341728152785), np.float64(114.91544567923043)]}\n",
      "  binner__clip: True\n",
      "  binner__fit_jointly: False\n",
      "  binner__joint_range_method: global\n",
      "  binner__n_bins: 8\n",
      "  binner__preserve_dataframe: False\n",
      "  binner__guidance_columns: None\n",
      "Modified binner n_bins to: 6\n",
      "Binner is still fitted after param change: False\n"
     ]
    }
   ],
   "source": [
    "# Sklearn pipeline integration\n",
    "print(\"=== Sklearn Pipeline Integration ===\")\n",
    "\n",
    "# Create a pipeline with binning and scaling\n",
    "pipeline = Pipeline([\n",
    "    ('binner', EqualWidthBinning(n_bins=8, clip=True)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "print(f\"Pipeline steps: {[step[0] for step in pipeline.steps]}\")\n",
    "\n",
    "# Split data for demonstration\n",
    "X_train, X_test = train_test_split(X_array, test_size=0.3, random_state=42)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Fit pipeline on training data\n",
    "pipeline.fit(X_train)\n",
    "print(\"Pipeline fitted successfully\")\n",
    "\n",
    "# Transform both training and test data\n",
    "X_train_transformed = pipeline.transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "print(f\"Transformed training shape: {X_train_transformed.shape}\")\n",
    "print(f\"Transformed test shape: {X_test_transformed.shape}\")\n",
    "\n",
    "# Check that binning step is fitted\n",
    "binner_from_pipeline = pipeline.named_steps['binner']\n",
    "print(f\"Binner is fitted: {binner_from_pipeline.is_fitted_}\")\n",
    "print(f\"Number of features in: {binner_from_pipeline.n_features_in_}\")\n",
    "\n",
    "# Show bin edges from pipeline\n",
    "print(f\"\\nBin edges from pipeline:\")\n",
    "for col, edges in binner_from_pipeline._bin_edges.items():\n",
    "    print(f\"  Column {col}: {len(edges)-1} bins, range [{edges[0]:.2f}, {edges[-1]:.2f}]\")\n",
    "\n",
    "# Check scaling statistics\n",
    "scaler_from_pipeline = pipeline.named_steps['scaler']\n",
    "print(f\"\\nScaler statistics (mean, std):\")\n",
    "for i, (mean, std) in enumerate(zip(scaler_from_pipeline.mean_, scaler_from_pipeline.scale_)):\n",
    "    print(f\"  Column {i}: mean={mean:.3f}, std={std:.3f}\")\n",
    "\n",
    "# Demonstrate get_params and set_params\n",
    "print(f\"\\n=== Pipeline Parameters ===\")\n",
    "params = pipeline.get_params()\n",
    "binner_params = {k: v for k, v in params.items() if k.startswith('binner__')}\n",
    "print(f\"Binner parameters in pipeline:\")\n",
    "for param, value in binner_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Modify parameters\n",
    "pipeline.set_params(binner__n_bins=6)\n",
    "print(f\"Modified binner n_bins to: {pipeline.get_params()['binner__n_bins']}\")\n",
    "\n",
    "# Show that we need to refit after parameter changes\n",
    "print(f\"Binner is still fitted after param change: {pipeline.named_steps['binner'].is_fitted_}\")\n",
    "# Note: Pipeline would need to be refit to use new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2fc74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-validation Demonstration ===\n",
      "Cross-validation MSE scores: [152.98084025 162.06780471 160.01265241 146.26959162 162.97065581]\n",
      "Mean CV MSE: 156.8603 (+/- 12.6998)\n",
      "Unbinned CV MSE: 0.2406 (+/- 0.0298)\n",
      "\n",
      "=== Grid Search for Optimal Bins ===\n",
      "Best parameters: {'binner__clip': True, 'binner__n_bins': 15}\n",
      "Best CV score: 17.4372\n",
      "Best binner config: n_bins=15, clip=True\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation with binning\n",
    "print(\"\\n=== Cross-validation Demonstration ===\")\n",
    "\n",
    "# Create a simple regression target\n",
    "np.random.seed(42)\n",
    "y_regression = X_array[:, 0] * 2 + X_array[:, 1] * -1 + np.random.normal(0, 0.5, X_array.shape[0])\n",
    "\n",
    "# Create a pipeline for regression\n",
    "reg_pipeline = Pipeline([\n",
    "    ('binner', EqualWidthBinning(n_bins=5)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(reg_pipeline, X_array, y_regression, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f\"Cross-validation MSE scores: {-cv_scores}\")\n",
    "print(f\"Mean CV MSE: {-cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Compare with unbinned data\n",
    "unbinned_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "cv_scores_unbinned = cross_val_score(unbinned_pipeline, X_array, y_regression, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Unbinned CV MSE: {-cv_scores_unbinned.mean():.4f} (+/- {cv_scores_unbinned.std() * 2:.4f})\")\n",
    "\n",
    "# Grid search demonstration\n",
    "print(\"\\n=== Grid Search for Optimal Bins ===\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'binner__n_bins': [3, 5, 8, 10, 15],\n",
    "    'binner__clip': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(reg_pipeline, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_array, y_regression)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Show the effect of different n_bins values\n",
    "best_binner = grid_search.best_estimator_.named_steps['binner']\n",
    "print(f\"Best binner config: n_bins={best_binner.n_bins}, clip={best_binner.clip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54041c",
   "metadata": {},
   "source": [
    "## 5. Parameter Serialization and Persistence\n",
    "\n",
    "The EqualWidthBinning class supports sklearn-style parameter serialization through `get_params()` and `set_params()`. This enables model persistence, hyperparameter tuning, and configuration management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c968b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parameter Serialization ===\n",
      "Original binner: EqualWidthBinning(n_bins=7, clip=True, preserve_dataframe=False, fit_jointly=False)\n",
      "Original fitted: True\n",
      "\n",
      "Extracted parameters:\n",
      "  bin_edges: {0: [np.float64(0.4632023004602859), np.float64(14.678711590196396), np.float64(28.894220879932504), np.float64(43.109730169668616), np.float64(57.32523945940473), np.float64(71.54074874914083), np.float64(85.75625803887694), np.float64(99.97176732861305)], 1: [np.float64(6.179742747580889), np.float64(19.282152857594035), np.float64(32.38456296760718), np.float64(45.48697307762032), np.float64(58.589383187633466), np.float64(71.69179329764661), np.float64(84.79420340765975), np.float64(97.8966135176729)], 2: [np.float64(0.00023269646100864647), np.float64(17.5111222938354), np.float64(35.02201189120979), np.float64(52.53290148858419), np.float64(70.04379108595857), np.float64(87.55468068333296), np.float64(105.06557028070736), np.float64(122.57645987808174)]}\n",
      "  bin_range: None\n",
      "  bin_representatives: {0: [np.float64(7.570956945328341), np.float64(21.786466235064452), np.float64(36.00197552480056), np.float64(50.217484814536675), np.float64(64.43299410427278), np.float64(78.64850339400888), np.float64(92.86401268374499)], 1: [np.float64(12.730947802587462), np.float64(25.833357912600608), np.float64(38.93576802261375), np.float64(52.038178132626896), np.float64(65.14058824264004), np.float64(78.24299835265319), np.float64(91.34540846266633)], 2: [np.float64(8.755677495148204), np.float64(26.266567092522596), np.float64(43.777456689896994), np.float64(61.28834628727138), np.float64(78.79923588464577), np.float64(96.31012548202017), np.float64(113.82101507939456)]}\n",
      "  clip: True\n",
      "  fit_jointly: False\n",
      "  joint_range_method: global\n",
      "  n_bins: 7\n",
      "  preserve_dataframe: False\n",
      "  guidance_columns: None\n",
      "\n",
      "Reconstructed binner: EqualWidthBinning(n_bins=7, clip=True, preserve_dataframe=False, bin_edges=..., bin_representatives=..., fit_jointly=False)\n",
      "Reconstructed fitted: True\n",
      "After fitting reconstructed: True\n",
      "\n",
      "Transformation comparison (first 5 rows):\n",
      "Original:      [[2 3 4]\n",
      " [6 1 0]\n",
      " [5 3 0]\n",
      " [4 4 0]\n",
      " [1 3 1]]\n",
      "Reconstructed: [[2 3 4]\n",
      " [6 1 0]\n",
      " [5 3 0]\n",
      " [4 4 0]\n",
      " [1 3 1]]\n",
      "Arrays equal: True\n",
      "\n",
      "=== Parameter Modification ===\n",
      "Original n_bins: 7\n",
      "Modified n_bins: 10\n",
      "Still fitted after param change: False\n",
      "Note: Parameter changes require refitting to take effect\n"
     ]
    }
   ],
   "source": [
    "# Parameter serialization demonstration\n",
    "print(\"=== Parameter Serialization ===\")\n",
    "\n",
    "# Create and fit a binner with specific configuration\n",
    "original_binner = EqualWidthBinning(n_bins=7, clip=True)\n",
    "original_binner.fit(X_array)\n",
    "\n",
    "print(f\"Original binner: {original_binner}\")\n",
    "print(f\"Original fitted: {original_binner.is_fitted_}\")\n",
    "\n",
    "# Get all parameters\n",
    "params = original_binner.get_params()\n",
    "print(f\"\\nExtracted parameters:\")\n",
    "for param, value in params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create a new instance from parameters\n",
    "reconstructed_binner = EqualWidthBinning(**params)\n",
    "print(f\"\\nReconstructed binner: {reconstructed_binner}\")\n",
    "print(f\"Reconstructed fitted: {reconstructed_binner.is_fitted_}\")\n",
    "\n",
    "# The reconstructed binner needs to be fitted\n",
    "reconstructed_binner.fit(X_array)\n",
    "print(f\"After fitting reconstructed: {reconstructed_binner.is_fitted_}\")\n",
    "\n",
    "# Compare transformations\n",
    "original_transformed = original_binner.transform(X_array[:5])\n",
    "reconstructed_transformed = reconstructed_binner.transform(X_array[:5])\n",
    "\n",
    "print(f\"\\nTransformation comparison (first 5 rows):\")\n",
    "print(f\"Original:      {original_transformed}\")\n",
    "print(f\"Reconstructed: {reconstructed_transformed}\")\n",
    "print(f\"Arrays equal: {np.array_equal(original_transformed, reconstructed_transformed)}\")\n",
    "\n",
    "# Demonstrate parameter modification\n",
    "print(f\"\\n=== Parameter Modification ===\")\n",
    "print(f\"Original n_bins: {original_binner.get_params()['n_bins']}\")\n",
    "\n",
    "# Modify parameters\n",
    "original_binner.set_params(n_bins=10)\n",
    "print(f\"Modified n_bins: {original_binner.get_params()['n_bins']}\")\n",
    "print(f\"Still fitted after param change: {original_binner.is_fitted_}\")\n",
    "\n",
    "# Note: After parameter changes, refitting is needed for changes to take effect\n",
    "print(\"Note: Parameter changes require refitting to take effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model persistence demonstration\n",
    "print(\"=== Model Persistence with Pickle ===\")\n",
    "\n",
    "import pickle\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create and fit a complex binner\n",
    "persistent_binner = EqualWidthBinning(n_bins=6, clip=True)\n",
    "persistent_binner.fit(X_array)\n",
    "\n",
    "# Transform some data\n",
    "original_result = persistent_binner.transform(X_array[:3])\n",
    "print(f\"Original transformation result:\\n{original_result}\")\n",
    "\n",
    "# Save to pickle\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp_file:\n",
    "    pickle.dump(persistent_binner, tmp_file)\n",
    "    pickle_path = tmp_file.name\n",
    "\n",
    "print(f\"Saved binner to: {pickle_path}\")\n",
    "\n",
    "# Load from pickle\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    loaded_binner = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded binner: {loaded_binner}\")\n",
    "print(f\"Loaded binner fitted: {loaded_binner.is_fitted_}\")\n",
    "\n",
    "# Compare parameters\n",
    "original_params = persistent_binner.get_params()\n",
    "loaded_params = loaded_binner.get_params()\n",
    "params_match = all(original_params[k] == loaded_params[k] for k in original_params.keys())\n",
    "print(f\"Parameters match: {params_match}\")\n",
    "\n",
    "# Compare transformations\n",
    "loaded_result = loaded_binner.transform(X_array[:3])\n",
    "print(f\"Loaded transformation result:\\n{loaded_result}\")\n",
    "print(f\"Results identical: {np.array_equal(original_result, loaded_result)}\")\n",
    "\n",
    "# Compare bin edges\n",
    "print(f\"\\nBin edges comparison:\")\n",
    "for col in range(X_array.shape[1]):\n",
    "    orig_edges = persistent_binner._bin_edges[col]\n",
    "    load_edges = loaded_binner._bin_edges[col]\n",
    "    edges_match = np.allclose(orig_edges, load_edges)\n",
    "    print(f\"  Column {col}: {edges_match} (original: {len(orig_edges)} edges, loaded: {len(load_edges)} edges)\")\n",
    "\n",
    "# Clean up\n",
    "os.unlink(pickle_path)\n",
    "print(f\"Cleaned up temporary file\")\n",
    "\n",
    "# JSON serialization of parameters (for configuration files)\n",
    "print(f\"\\n=== JSON-serializable Parameters ===\")\n",
    "import json\n",
    "\n",
    "# Get parameters and make them JSON serializable\n",
    "json_params = {}\n",
    "for key, value in persistent_binner.get_params().items():\n",
    "    if isinstance(value, (str, int, float, bool, type(None))):\n",
    "        json_params[key] = value\n",
    "    else:\n",
    "        json_params[key] = str(value)  # Convert complex objects to string\n",
    "\n",
    "json_str = json.dumps(json_params, indent=2)\n",
    "print(f\"JSON parameters:\\n{json_str}\")\n",
    "\n",
    "# Parse back (note: strategy would need special handling for full reconstruction)\n",
    "parsed_params = json.loads(json_str)\n",
    "print(f\"Parsed back: {parsed_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb62cb9",
   "metadata": {},
   "source": [
    "## 6. Advanced Features\n",
    "\n",
    "This section demonstrates advanced features of EqualWidthBinning including pre-fitted bins, joint fitting across datasets, and edge case handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-fitted bins demonstration\n",
    "print(\"=== Pre-fitted Bins ===\")\n",
    "\n",
    "# Define custom bin edges for each column\n",
    "custom_bin_edges = {\n",
    "    0: np.array([-2.0, -1.0, 0.0, 1.0, 2.0]),  # 4 bins for column 0\n",
    "    1: np.array([-1.5, -0.5, 0.5, 1.5]),       # 3 bins for column 1\n",
    "    2: np.array([0.0, 0.5, 1.0, 1.5, 2.0, 3.0]) # 5 bins for column 2\n",
    "}\n",
    "\n",
    "# Create binner with pre-specified edges (automatically fitted)\n",
    "prefitted_binner = EqualWidthBinning(bin_edges=custom_bin_edges)\n",
    "print(f\"Pre-fitted binner: {prefitted_binner}\")\n",
    "print(f\"Is fitted without calling fit(): {prefitted_binner.is_fitted_}\")\n",
    "\n",
    "# Can transform immediately without calling fit()\n",
    "test_data = np.array([[0.5, 0.2, 1.2], [-0.8, -0.3, 0.8], [1.5, 1.0, 2.5]])\n",
    "prefitted_result = prefitted_binner.transform(test_data)\n",
    "print(f\"Pre-fitted transformation:\\n{prefitted_result}\")\n",
    "\n",
    "# Show the bin edges that were used\n",
    "print(f\"Bin edges used:\")\n",
    "for col, edges in prefitted_binner._bin_edges.items():\n",
    "    print(f\"  Column {col}: {edges}\")\n",
    "\n",
    "# Joint fitting demonstration\n",
    "print(f\"\\n=== Joint Fitting ===\")\n",
    "\n",
    "# Create separate train and validation sets with different distributions\n",
    "np.random.seed(42)\n",
    "X_train = np.random.normal(0, 1, (100, 3))\n",
    "X_val = np.random.normal(0.5, 1.2, (50, 3))  # Slightly different distribution\n",
    "\n",
    "print(f\"Training data range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "print(f\"Validation data range: [{X_val.min():.2f}, {X_val.max():.2f}]\")\n",
    "\n",
    "# Fit on training data only\n",
    "train_only_binner = EqualWidthBinning(n_bins=5)\n",
    "train_only_binner.fit(X_train)\n",
    "\n",
    "# Fit jointly on both datasets\n",
    "joint_binner = EqualWidthBinning(n_bins=5)\n",
    "joint_data = np.vstack([X_train, X_val])\n",
    "joint_binner.fit(joint_data)\n",
    "\n",
    "print(f\"\\nBin ranges comparison:\")\n",
    "for col in range(3):\n",
    "    train_edges = train_only_binner._bin_edges[col]\n",
    "    joint_edges = joint_binner._bin_edges[col]\n",
    "    print(f\"Column {col}:\")\n",
    "    print(f\"  Train only: [{train_edges[0]:.2f}, {train_edges[-1]:.2f}]\")\n",
    "    print(f\"  Joint fit:  [{joint_edges[0]:.2f}, {joint_edges[-1]:.2f}]\")\n",
    "\n",
    "# Show how this affects validation data transformation\n",
    "val_train_binned = train_only_binner.transform(X_val[:3])\n",
    "val_joint_binned = joint_binner.transform(X_val[:3])\n",
    "\n",
    "print(f\"\\nValidation data binning (first 3 rows):\")\n",
    "print(f\"Original:     {X_val[:3]}\")\n",
    "print(f\"Train-fitted: {val_train_binned}\")\n",
    "print(f\"Joint-fitted: {val_joint_binned}\")\n",
    "\n",
    "# Check for out-of-bounds issues with train-only binner\n",
    "val_clipped = train_only_binner.transform(X_val, clip=True)[:3]\n",
    "print(f\"Train-fitted with clipping: {val_clipped}\")\n",
    "\n",
    "# Clipping demonstration\n",
    "print(f\"\\n=== Clipping Behavior ===\")\n",
    "\n",
    "# Create data with extreme outliers\n",
    "outlier_data = np.array([[-5.0, 3.0, 10.0], [0.0, 0.0, 0.0], [5.0, -3.0, -5.0]])\n",
    "\n",
    "# Transform with and without clipping\n",
    "no_clip_result = joint_binner.transform(outlier_data, clip=False)\n",
    "clip_result = joint_binner.transform(outlier_data, clip=True)\n",
    "\n",
    "print(f\"Outlier data: {outlier_data}\")\n",
    "print(f\"Without clipping: {no_clip_result}\")\n",
    "print(f\"With clipping: {clip_result}\")\n",
    "\n",
    "# Show what the bin assignments mean\n",
    "print(f\"Bin edge interpretation for column 0:\")\n",
    "col0_edges = joint_binner._bin_edges[0]\n",
    "print(f\"  Edges: {col0_edges}\")\n",
    "print(f\"  -5.0 maps to bin: {no_clip_result[0, 0]} (no clip), {clip_result[0, 0]} (clip)\")\n",
    "print(f\"  5.0 maps to bin: {no_clip_result[2, 0]} (no clip), {clip_result[2, 0]} (clip)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
