{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acac04d",
   "metadata": {},
   "source": [
    "# 🎯 Manual and Domain-Driven Binning Methods: Expert Knowledge Integration\n",
    "\n",
    "Welcome to a comprehensive exploration of manual and domain-driven binning methods in the `binlearn` package. These powerful techniques enable you to incorporate expert knowledge, business rules, and domain-specific requirements directly into your data preprocessing pipeline.\n",
    "\n",
    "## 🔧 Overview of Manual Binning Approaches\n",
    "\n",
    "Manual binning methods bridge the gap between automated algorithms and real-world requirements. They allow data scientists to encode domain expertise, regulatory constraints, and business logic directly into the binning process, ensuring that the resulting bins are not only statistically meaningful but also practically relevant.\n",
    "\n",
    "## 🛠️ Methods Covered in This Notebook\n",
    "\n",
    "### **ManualIntervalBinning** 📐\n",
    "- **Principle**: Define explicit breakpoints based on domain knowledge or business rules\n",
    "- **Strengths**: Full control over boundaries, incorporates expert knowledge, interpretable\n",
    "- **Best for**: Industry standards, regulatory thresholds, established business segments\n",
    "- **Examples**: Credit score ranges, age groups, income brackets\n",
    "\n",
    "### **ManualFlexibleBinning** 🔧\n",
    "- **Principle**: Create complex, customizable bin patterns with flexible rules and conditions\n",
    "- **Strengths**: Maximum flexibility, handles irregular patterns, supports complex logic\n",
    "- **Best for**: Multi-criteria binning, complex business rules, mixed data types\n",
    "- **Examples**: Customer segmentation, risk categorization, performance tiers\n",
    "\n",
    "### **SingletonBinning** 🔹\n",
    "- **Principle**: Preserve unique values as individual bins, maintaining categorical integrity\n",
    "- **Strengths**: No information loss, perfect for discrete data, maintains exact values\n",
    "- **Best for**: Categorical data, unique identifiers, discrete ordinal scales\n",
    "- **Examples**: Product categories, geographic regions, discrete ratings\n",
    "\n",
    "## 🎯 Key Advantages of Manual Binning\n",
    "\n",
    "✅ **Domain Expertise Integration**: Leverage years of industry knowledge and experience  \n",
    "✅ **Business Alignment**: Ensure bins match existing business processes and terminology  \n",
    "✅ **Regulatory Compliance**: Meet specific legal, regulatory, or compliance requirements  \n",
    "✅ **Stakeholder Buy-in**: Create interpretable bins that resonate with business users  \n",
    "✅ **Consistency**: Maintain consistent binning across different projects and teams  \n",
    "✅ **Flexibility**: Handle complex, irregular, or multi-criteria binning scenarios  \n",
    "\n",
    "## 🎯 Strategic Applications\n",
    "\n",
    "### **Industry Standards & Regulations** 📋\n",
    "- Credit scoring (FICO ranges: 300-579, 580-669, 670-739, 740-799, 800-850)\n",
    "- Healthcare risk categories (Low, Moderate, High, Critical)\n",
    "- Financial risk assessment (Basel III compliance tiers)\n",
    "- Environmental impact levels (EPA standards)\n",
    "\n",
    "### **Business Process Integration** 🏢\n",
    "- Customer lifecycle stages (Prospect, New, Active, Loyal, At-Risk, Churned)\n",
    "- Sales performance tiers (Bronze, Silver, Gold, Platinum)\n",
    "- Product pricing categories (Economy, Standard, Premium, Luxury)\n",
    "- Geographic market segments (Local, Regional, National, International)\n",
    "\n",
    "### **Data Quality & Governance** 🛡️\n",
    "- Maintaining categorical integrity\n",
    "- Standardizing across different data sources\n",
    "- Ensuring reproducible and auditable binning\n",
    "- Supporting data lineage and documentation requirements\n",
    "\n",
    "## 🔄 When to Choose Manual Binning Methods\n",
    "\n",
    "### **Ideal Scenarios** ⭐\n",
    "- Strong domain expertise is available\n",
    "- Regulatory or compliance requirements exist\n",
    "- Business stakeholder alignment is critical\n",
    "- Existing binning standards must be maintained\n",
    "- Interpretability is paramount\n",
    "- Complex, multi-criteria binning is needed\n",
    "\n",
    "### **Consider Alternatives When** ⚠️\n",
    "- Exploring new domains without established knowledge\n",
    "- Automated pattern discovery is preferred\n",
    "- Large-scale feature engineering with many variables\n",
    "- Rapid prototyping and experimentation phases\n",
    "- Domain knowledge is limited or uncertain\n",
    "\n",
    "## 📚 What You'll Learn\n",
    "\n",
    "1. **Expert Knowledge Integration**: How to encode domain expertise into binning rules\n",
    "2. **Business Rule Implementation**: Translating business logic into technical specifications\n",
    "3. **Regulatory Compliance**: Meeting specific industry and legal requirements\n",
    "4. **Interpretability Optimization**: Creating bins that stakeholders understand and trust\n",
    "5. **Flexibility Showcase**: Handling complex, irregular, and multi-criteria scenarios\n",
    "6. **Quality Assurance**: Validation and testing of manual binning rules\n",
    "7. **Best Practices**: Guidelines for maintainable and scalable manual binning\n",
    "\n",
    "Let's explore how to effectively leverage domain knowledge in your binning strategy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import manual binning methods from binlearn\n",
    "from binlearn.methods import ManualIntervalBinning, SingletonBinning\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"📝 Manual and Domain-Driven Binning Methods\")\n",
    "print(\"=\" * 50)\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(f\"📊 NumPy version: {np.__version__}\")\n",
    "print(f\"🐼 Pandas version: {pd.__version__}\")\n",
    "print(f\"🎯 Methods: ManualInterval, SingletonBinning\")\n",
    "print(f\"💼 Focus: Leveraging domain expertise for intelligent binning!\")\n",
    "print(f\"🏢 Use cases: Credit scoring, demographics, regulatory compliance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41baad3f",
   "metadata": {},
   "source": [
    "## 1. Real-World Scenarios\n",
    "\n",
    "Let's create realistic datasets that benefit from domain knowledge and manual binning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ad7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic datasets for manual binning demonstrations\n",
    "print(\"🏢 Creating Real-World Datasets\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Dataset 1: Credit Scores (Standard industry breakpoints)\n",
    "np.random.seed(42)\n",
    "credit_scores = np.random.beta(2, 2, 1000) * 400 + 300  # Scale to 300-700 range\n",
    "credit_scores = np.clip(credit_scores, 300, 850)  # Realistic FICO range\n",
    "\n",
    "# Dataset 2: Customer Ages (Business-relevant age groups)\n",
    "age_groups = np.concatenate([\n",
    "    np.random.normal(25, 5, 200),  # Young adults\n",
    "    np.random.normal(40, 8, 300),  # Middle-aged\n",
    "    np.random.normal(60, 10, 200)  # Seniors\n",
    "])\n",
    "age_groups = np.clip(age_groups, 18, 85)\n",
    "\n",
    "# Dataset 3: Income levels (Tax bracket-based)\n",
    "income_levels = np.concatenate([\n",
    "    np.random.lognormal(10.5, 0.5, 400),   # Lower income\n",
    "    np.random.lognormal(11.2, 0.3, 300),   # Middle income  \n",
    "    np.random.lognormal(12.0, 0.4, 200),   # Higher income\n",
    "    np.random.lognormal(13.0, 0.6, 100)    # High income\n",
    "])\n",
    "\n",
    "# Dataset 4: Product ratings (discrete values)\n",
    "product_ratings = np.random.choice([1, 2, 3, 4, 5], size=800, \n",
    "                                 p=[0.05, 0.10, 0.25, 0.35, 0.25])\n",
    "\n",
    "# Dataset 5: Medical test results (clinical thresholds)\n",
    "glucose_levels = np.random.gamma(2, 50, 600)  # mg/dL\n",
    "glucose_levels = np.clip(glucose_levels, 70, 400)\n",
    "\n",
    "# Create comprehensive DataFrame\n",
    "df_manual = pd.DataFrame({\n",
    "    'credit_score': credit_scores,\n",
    "    'age': age_groups,\n",
    "    'income': income_levels,\n",
    "    'rating': np.random.choice(product_ratings, len(credit_scores)),\n",
    "    'glucose': np.random.choice(glucose_levels, len(credit_scores))\n",
    "})\n",
    "\n",
    "# Visualize the raw data\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each feature\n",
    "features = ['credit_score', 'age', 'income', 'rating', 'glucose']\n",
    "titles = [\n",
    "    'Credit Scores\\n(Industry Standard Ranges)',\n",
    "    'Customer Ages\\n(Life Stage Groups)',\n",
    "    'Income Levels\\n(Tax Bracket Based)',\n",
    "    'Product Ratings\\n(Discrete Values)',\n",
    "    'Glucose Levels\\n(Clinical Thresholds)'\n",
    "]\n",
    "\n",
    "colors = ['lightcoral', 'skyblue', 'lightgreen', 'orange', 'plum']\n",
    "\n",
    "for i, (feature, title, color) in enumerate(zip(features, titles, colors)):\n",
    "    if feature == 'rating':\n",
    "        # Bar plot for discrete ratings\n",
    "        rating_counts = df_manual[feature].value_counts().sort_index()\n",
    "        axes[i].bar(rating_counts.index, rating_counts.values, color=color, alpha=0.7, edgecolor='black')\n",
    "        axes[i].set_xticks(rating_counts.index)\n",
    "    else:\n",
    "        # Histogram for continuous features\n",
    "        axes[i].hist(df_manual[feature], bins=30, alpha=0.7, color=color, edgecolor='black')\n",
    "    \n",
    "    axes[i].set_title(title, fontweight='bold')\n",
    "    axes[i].set_xlabel(feature.replace('_', ' ').title())\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n📊 Dataset Summary Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(df_manual.describe().round(2))\n",
    "\n",
    "print(f\"\\n✅ Generated realistic datasets:\")\n",
    "print(f\"   • Credit scores: {len(credit_scores)} samples (300-850 range)\")\n",
    "print(f\"   • Ages: {len(age_groups)} samples (18-85 range)\")\n",
    "print(f\"   • Income: {len(income_levels)} samples (log-normal distribution)\")\n",
    "print(f\"   • Ratings: {len(product_ratings)} samples (1-5 discrete)\")\n",
    "print(f\"   • Glucose: {len(glucose_levels)} samples (70-400 mg/dL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f261e6",
   "metadata": {},
   "source": [
    "## 2. Manual Interval Binning - Industry Standards\n",
    "\n",
    "Using established industry breakpoints and regulatory thresholds for meaningful business categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d2e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 Manual Interval Binning with Industry Standards\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Define industry-standard breakpoints\n",
    "domain_breakpoints = {\n",
    "    'credit_score': {\n",
    "        'breakpoints': [300, 580, 670, 740, 800, 850],\n",
    "        'labels': ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent'],\n",
    "        'description': 'FICO Credit Score Categories'\n",
    "    },\n",
    "    'age': {\n",
    "        'breakpoints': [18, 25, 35, 50, 65, 85],\n",
    "        'labels': ['Gen Z', 'Millennials', 'Gen X', 'Boomers', 'Silent'],\n",
    "        'description': 'Generational Cohorts'\n",
    "    },\n",
    "    'income': {\n",
    "        'breakpoints': [0, 30000, 60000, 100000, 200000, np.inf],\n",
    "        'labels': ['Low', 'Lower-Mid', 'Middle', 'Upper-Mid', 'High'],\n",
    "        'description': 'Income Brackets (USD)'\n",
    "    },\n",
    "    'glucose': {\n",
    "        'breakpoints': [0, 100, 125, 200, 400],\n",
    "        'labels': ['Normal', 'Prediabetic', 'Diabetic', 'Severe'],\n",
    "        'description': 'Clinical Glucose Levels (mg/dL)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Apply manual interval binning\n",
    "manual_results = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (feature, config) in enumerate(domain_breakpoints.items()):\n",
    "    print(f\"\\n🎯 Processing {feature} - {config['description']}\")\n",
    "    \n",
    "    # Create manual interval binner\n",
    "    binner = ManualIntervalBinning(\n",
    "        intervals={feature: config['breakpoints']}\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    feature_data = df_manual[[feature]]\n",
    "    binner.fit(feature_data)\n",
    "    binned_data = binner.transform(feature_data)\n",
    "    \n",
    "    # Store results\n",
    "    manual_results[feature] = {\n",
    "        'binner': binner,\n",
    "        'original': feature_data,\n",
    "        'binned': binned_data,\n",
    "        'breakpoints': config['breakpoints'],\n",
    "        'labels': config['labels']\n",
    "    }\n",
    "    \n",
    "    # Create visualization\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot original distribution\n",
    "    original_vals = feature_data[feature].values\n",
    "    ax.hist(original_vals, bins=30, alpha=0.6, color='lightblue', \n",
    "           label='Original Distribution', density=True)\n",
    "    \n",
    "    # Add breakpoint lines\n",
    "    for j, breakpoint in enumerate(config['breakpoints']):\n",
    "        if breakpoint != np.inf and breakpoint != 0:\n",
    "            ax.axvline(breakpoint, color='red', linestyle='--', alpha=0.8, linewidth=2)\n",
    "            if j < len(config['labels']):\n",
    "                # Add label at midpoint of bin\n",
    "                if j == 0:\n",
    "                    mid_point = (original_vals.min() + breakpoint) / 2\n",
    "                elif j == len(config['breakpoints']) - 1:\n",
    "                    mid_point = (config['breakpoints'][j-1] + original_vals.max()) / 2\n",
    "                else:\n",
    "                    mid_point = (config['breakpoints'][j-1] + breakpoint) / 2\n",
    "                \n",
    "                ax.text(mid_point, ax.get_ylim()[1] * 0.8, config['labels'][j], \n",
    "                       rotation=90, ha='center', va='bottom', fontweight='bold',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    ax.set_title(f\"{config['description']}\\n{feature.replace('_', ' ').title()}\", fontweight='bold')\n",
    "    ax.set_xlabel(feature.replace('_', ' ').title())\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Print bin statistics\n",
    "    bin_counts = binned_data[feature].value_counts().sort_index()\n",
    "    print(f\"   📊 Bin distribution:\")\n",
    "    for bin_val, count in bin_counts.items():\n",
    "        percentage = (count / len(binned_data)) * 100\n",
    "        if bin_val < len(config['labels']):\n",
    "            label = config['labels'][int(bin_val)]\n",
    "            print(f\"      {label}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Applied manual interval binning to {len(domain_breakpoints)} features\")\n",
    "print(\"📋 All breakpoints based on established industry standards\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
